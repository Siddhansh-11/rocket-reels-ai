"""
B-roll Search Agent for Production Workflow

This agent searches for relevant b-roll footage using Pexels API
based on the prompts generated by the prompt generation agent.
"""

import os
import json
import requests
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional, Union
from langchain_core.tools import tool
from dotenv import load_dotenv
from pathlib import Path
import hashlib
from datetime import datetime

# Load environment variables
load_dotenv()

# Pexels API configuration
PEXELS_API_KEY = os.getenv("PEXELS_API_KEY")
if not PEXELS_API_KEY:
    raise ValueError("PEXELS_API_KEY not found in environment variables")

PEXELS_IMAGE_URL = "https://api.pexels.com/v1/search"
PEXELS_VIDEO_URL = "https://api.pexels.com/videos/search"

async def search_broll_from_prompts(prompts_data: List[Dict[str, Any]]) -> str:
    """
    Search for b-roll content (images and videos) from Pexels based on generated prompts.
    
    Args:
        prompts_data: List of prompt dictionaries containing:
            - prompt: The visual description/prompt text
            - id: Prompt ID
            - type: Scene type
            - timing: Scene timing info
            - style: Visual style
    
    Returns:
        JSON string containing found b-roll assets with metadata
    """
    try:
        if not prompts_data:
            return json.dumps({
                "error": "No prompts provided for b-roll search",
                "images": [],
                "videos": []
            })
        
        # Search for b-roll content
        broll_results = {
            "images": [],
            "videos": [],
            "metadata": {
                "total_prompts": len(prompts_data),
                "source": "Pexels"
            }
        }
        
        headers = {"Authorization": PEXELS_API_KEY}
        
        for prompt_info in prompts_data:
            prompt_text = prompt_info.get("prompt", "")
            prompt_id = prompt_info.get("id", "unknown")
            scene_type = prompt_info.get("type", "scene")
            timing = prompt_info.get("timing", "")
            
            if not prompt_text:
                continue
            
            # Extract key search terms from the prompt
            search_query = _simplify_prompt_for_search(prompt_text)
            
            print(f"Searching b-roll for prompt {prompt_id}: '{search_query}'")
            
            # Search for images
            try:
                img_response = requests.get(
                    PEXELS_IMAGE_URL,
                    headers=headers,
                    params={"query": search_query, "per_page": 3}
                )
                img_response.raise_for_status()
                img_data = img_response.json()
                
                for photo in img_data.get("photos", [])[:2]:
                    broll_results["images"].append({
                        "url": photo["src"]["large"],
                        "thumbnail": photo["src"]["medium"],
                        "photographer": photo.get("photographer", "Unknown"),
                        "query": search_query,
                        "prompt_id": prompt_id,
                        "scene_type": scene_type,
                        "timing": timing,
                        "width": photo.get("width", 0),
                        "height": photo.get("height", 0),
                        "pexels_id": photo.get("id", ""),
                        "alt": photo.get("alt", search_query),
                        "original_prompt": prompt_text
                    })
            except Exception as e:
                print(f"Error searching images for prompt {prompt_id}: {str(e)}")
            
            # Search for videos
            try:
                vid_response = requests.get(
                    PEXELS_VIDEO_URL,
                    headers=headers,
                    params={"query": search_query, "per_page": 2}
                )
                vid_response.raise_for_status()
                vid_data = vid_response.json()
                
                for video in vid_data.get("videos", [])[:1]:
                    if video.get("video_files"):
                        # Get HD quality video file
                        video_file = next(
                            (f for f in video["video_files"] if f.get("quality") == "hd"),
                            video["video_files"][0]
                        )
                        broll_results["videos"].append({
                            "url": video_file["link"],
                            "width": video_file.get("width", 0),
                            "height": video_file.get("height", 0),
                            "duration": video.get("duration", 0),
                            "query": search_query,
                            "prompt_id": prompt_id,
                            "scene_type": scene_type,
                            "timing": timing,
                            "pexels_id": video.get("id", ""),
                            "user": video.get("user", {}).get("name", "Unknown"),
                            "original_prompt": prompt_text
                        })
            except Exception as e:
                print(f"Error searching videos for prompt {prompt_id}: {str(e)}")
        
        # Add summary
        broll_results["metadata"]["images_found"] = len(broll_results["images"])
        broll_results["metadata"]["videos_found"] = len(broll_results["videos"])
        broll_results["metadata"]["search_completed"] = True
        
        print(f"B-roll search complete: {len(broll_results['images'])} images, {len(broll_results['videos'])} videos")
        
        return json.dumps(broll_results, indent=2)
        
    except Exception as e:
        error_result = {
            "error": f"B-roll search failed: {str(e)}",
            "images": [],
            "videos": [],
            "metadata": {"status": "failed"}
        }
        return json.dumps(error_result, indent=2)

def _simplify_prompt_for_search(prompt_text: str) -> str:
    """
    Simplify a detailed image generation prompt into search keywords for Pexels.
    
    Args:
        prompt_text: Full prompt text (e.g., "A futuristic AI robot working on a computer...")
    
    Returns:
        Simplified search query for Pexels
    """
    # Remove style descriptors and technical terms
    style_terms = [
        "photorealistic", "cinematic", "4k", "8k", "ultra detailed", "high quality",
        "professional", "dramatic lighting", "shallow depth of field", "bokeh",
        "vibrant colors", "moody", "atmospheric", "studio lighting", "golden hour",
        "blue hour", "high contrast", "soft lighting", "harsh lighting",
        "wide angle", "close up", "medium shot", "establishing shot",
        "rule of thirds", "symmetrical composition", "minimalist", "maximalist"
    ]
    
    # Convert to lowercase for processing
    search_text = prompt_text.lower()
    
    # Remove style terms
    for term in style_terms:
        search_text = search_text.replace(term.lower(), "")
    
    # Extract key subjects and actions
    # Common patterns: "a/an [subject] [action]" or "[subject] [action]"
    import re
    
    # Remove articles and clean up
    search_text = re.sub(r'\b(a|an|the)\b', '', search_text)
    search_text = re.sub(r'[,\.\!\?;:\'"()]', ' ', search_text)
    search_text = re.sub(r'\s+', ' ', search_text).strip()
    
    # Extract first few meaningful words
    words = search_text.split()
    
    # Filter out common filler words
    filler_words = {
        "with", "and", "or", "but", "in", "on", "at", "to", "for", "of",
        "by", "from", "up", "down", "out", "over", "under", "again",
        "further", "then", "once", "very", "really", "just", "quite"
    }
    
    meaningful_words = [w for w in words if w not in filler_words and len(w) > 2]
    
    # Take first 3-5 meaningful words
    search_query = " ".join(meaningful_words[:5])
    
    # If query is too short, use more words
    if len(search_query) < 10 and len(meaningful_words) > 5:
        search_query = " ".join(meaningful_words[:7])
    
    return search_query.strip()

@tool  
async def organize_broll_assets(broll_data: Dict[str, Any], project_folder_path: str) -> str:
    """
    Organize b-roll assets by creating a metadata file in the project folder.
    This doesn't download files but creates references for the editor.
    
    Args:
        broll_data: Dictionary containing b-roll search results
        project_folder_path: Path to the Google Drive project folder
        
    Returns:
        Status message about organization
    """
    try:
        from pathlib import Path
        
        # Create b-roll metadata file
        broll_metadata = {
            "generated_at": os.environ.get("CURRENT_TIMESTAMP", "unknown"),
            "total_assets": {
                "images": len(broll_data.get("images", [])),
                "videos": len(broll_data.get("videos", []))
            },
            "assets": {
                "images": broll_data.get("images", []),
                "videos": broll_data.get("videos", [])
            },
            "source": "Pexels API"
        }
        
        # Create broll directory path
        broll_dir = Path(project_folder_path) / "broll"
        metadata_path = broll_dir / "broll_metadata.json"
        
        # Format for display
        result = f"""B-roll assets organized successfully:

Location: {broll_dir}
Total Images: {len(broll_data.get('images', []))}
Total Videos: {len(broll_data.get('videos', []))}

Metadata saved to: {metadata_path}

Sample B-roll Assets:
"""
        
        # Add sample assets
        for i, img in enumerate(broll_data.get("images", [])[:3], 1):
            result += f"\nImage {i}:"
            result += f"\n  - Prompt: {img.get('original_prompt', 'N/A')[:50]}..."
            result += f"\n  - URL: {img.get('url', 'N/A')}"
            result += f"\n  - Timing: {img.get('timing', 'N/A')}"
        
        for i, vid in enumerate(broll_data.get("videos", [])[:2], 1):
            result += f"\n\nVideo {i}:"
            result += f"\n  - Prompt: {vid.get('original_prompt', 'N/A')[:50]}..."
            result += f"\n  - Duration: {vid.get('duration', 0)}s"
            result += f"\n  - URL: {vid.get('url', 'N/A')}"
        
        return result
        
    except Exception as e:
        return f"Failed to organize b-roll assets: {str(e)}"

async def _download_file(session: aiohttp.ClientSession, url: str, filepath: Path, retries: int = 3) -> bool:
    """Download a file with retry logic."""
    for attempt in range(retries):
        try:
            async with session.get(url) as response:
                if response.status == 200:
                    content = await response.read()
                    filepath.write_bytes(content)
                    return True
                else:
                    print(f"Failed to download {url}: HTTP {response.status}")
        except Exception as e:
            print(f"Download error attempt {attempt + 1}/{retries}: {str(e)}")
            if attempt < retries - 1:
                await asyncio.sleep(1)
    return False

async def search_and_download_broll(prompts_data: List[Dict[str, Any]], download_path: Optional[str] = None) -> str:
    """
    Search for b-roll content from Pexels and download assets locally.
    
    Args:
        prompts_data: List of prompt dictionaries containing id, prompt, type, timing, style
        download_path: Optional path to download assets (defaults to temp directory)
    
    Returns:
        JSON string with search results and downloaded file paths
    """
    try:
        if not prompts_data:
            return json.dumps({
                "error": "No prompts provided for b-roll search",
                "images": [],
                "videos": [],
                "downloaded_files": []
            })
        
        # Create download directory
        if download_path:
            download_dir = Path(download_path)
        else:
            base_dir = Path(__file__).parent.parent
            download_dir = base_dir / "temp_broll" / f"broll_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        download_dir.mkdir(parents=True, exist_ok=True)
        
        # First, search for all b-roll
        search_results = json.loads(await search_broll_from_prompts(prompts_data))
        
        if search_results.get("error"):
            return json.dumps(search_results)
        
        # Download assets
        downloaded_files = []
        
        async with aiohttp.ClientSession() as session:
            # Download images
            for i, image in enumerate(search_results.get("images", [])):
                try:
                    url = image.get("url")
                    if not url:
                        continue
                    
                    # Generate filename
                    prompt_id = image.get("prompt_id", "unknown")
                    pexels_id = image.get("pexels_id", hashlib.md5(url.encode()).hexdigest()[:8])
                    filename = f"image_{prompt_id}_{pexels_id}.jpg"
                    filepath = download_dir / filename
                    
                    print(f"Downloading image {i+1}/{len(search_results['images'])}: {filename}")
                    
                    if await _download_file(session, url, filepath):
                        image["local_path"] = str(filepath)
                        downloaded_files.append({
                            "type": "image",
                            "filename": filename,
                            "path": str(filepath),
                            "url": url,
                            "prompt_id": prompt_id,
                            "scene_type": image.get("scene_type"),
                            "timing": image.get("timing"),
                            "photographer": image.get("photographer")
                        })
                        print(f"✓ Downloaded: {filename}")
                    else:
                        print(f"✗ Failed to download: {filename}")
                        
                except Exception as e:
                    print(f"Error downloading image: {str(e)}")
            
            # Download videos
            for i, video in enumerate(search_results.get("videos", [])):
                try:
                    url = video.get("url")
                    if not url:
                        continue
                    
                    # Generate filename
                    prompt_id = video.get("prompt_id", "unknown")
                    pexels_id = video.get("pexels_id", hashlib.md5(url.encode()).hexdigest()[:8])
                    filename = f"video_{prompt_id}_{pexels_id}.mp4"
                    filepath = download_dir / filename
                    
                    print(f"Downloading video {i+1}/{len(search_results['videos'])}: {filename}")
                    
                    if await _download_file(session, url, filepath):
                        video["local_path"] = str(filepath)
                        downloaded_files.append({
                            "type": "video",
                            "filename": filename,
                            "path": str(filepath),
                            "url": url,
                            "prompt_id": prompt_id,
                            "scene_type": video.get("scene_type"),
                            "timing": video.get("timing"),
                            "duration": video.get("duration"),
                            "user": video.get("user")
                        })
                        print(f"✓ Downloaded: {filename}")
                    else:
                        print(f"✗ Failed to download: {filename}")
                        
                except Exception as e:
                    print(f"Error downloading video: {str(e)}")
        
        # Update results with download information
        search_results["download_directory"] = str(download_dir)
        search_results["downloaded_files"] = downloaded_files
        search_results["metadata"]["downloads_completed"] = True
        search_results["metadata"]["total_downloaded"] = len(downloaded_files)
        
        print(f"\nB-roll download complete: {len(downloaded_files)} files downloaded to {download_dir}")
        
        return json.dumps(search_results, indent=2)
        
    except Exception as e:
        error_result = {
            "error": f"B-roll search and download failed: {str(e)}",
            "images": [],
            "videos": [],
            "downloaded_files": []
        }
        return json.dumps(error_result, indent=2)

# Create tool wrapper for search_broll_from_prompts
@tool
async def search_broll_from_prompts_tool(prompts_data: List[Dict[str, Any]]) -> str:
    """
    Tool wrapper for search_broll_from_prompts function.
    
    Args:
        prompts_data: List of prompt dictionaries
    
    Returns:
        JSON string containing found b-roll assets with metadata
    """
    return await search_broll_from_prompts(prompts_data)

# Create tool wrapper for search_and_download_broll
@tool
async def search_and_download_broll_tool(prompts_data: List[Dict[str, Any]]) -> str:
    """
    Tool wrapper for search_and_download_broll function.
    
    Args:
        prompts_data: List of prompt dictionaries
    
    Returns:
        JSON string with search results and downloaded file paths
    """
    return await search_and_download_broll(prompts_data)

# Export tools for the workflow
broll_search_tools = [search_broll_from_prompts_tool, organize_broll_assets, search_and_download_broll_tool]